{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT=PosixPath('/Users/tug/Work/projects/neuralstream/synchro-python')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(os.path.abspath('')).parent\n",
    "print(f\"{PROJECT_ROOT=}\")\n",
    "\n",
    "log_file = \"/Users/tug/Downloads/leo_mic (4).log\"\n",
    "transalation_file = \"/Users/tug/Work/projects/neuralstream/synchro-python/sources/4.txt\"\n",
    "config_file = \"/Users/tug/Work/projects/neuralstream/synchro-python/config.local.json\"\n",
    "\n",
    "report_raw_file = \"/Users/tug/Downloads/report.json\"\n",
    "report_html_file = \"/Users/tug/Downloads/report.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def calculate_bleu(reference_text, candidate_text):\n",
    "    \"\"\"\n",
    "    Подробнее в bleu.ipynb\n",
    "    \"\"\"\n",
    "    # Токенизация\n",
    "    reference_tokens = [word_tokenize(reference_text)]\n",
    "    candidate_tokens = word_tokenize(candidate_text)\n",
    "\n",
    "    # Расчёт BLEU\n",
    "    smoothing = SmoothingFunction().method1\n",
    "    return sentence_bleu(reference_tokens, candidate_tokens, smoothing_function=smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "\n",
    "\n",
    "def translate(text: str, source: str = \"en\", target: str = \"ru\") -> str:\n",
    "    # Кешируем инстанс переводчика\n",
    "    translator = getattr(translate, \"instance\", None)\n",
    "    if translator is None:\n",
    "        translator = Translator(from_lang=source, to_lang=target)\n",
    "    else:\n",
    "        setattr(translate, \"instance\", translator)\n",
    "\n",
    "    # Переводим текст, если получается, иначе оставляем как есть\n",
    "    try:\n",
    "        result = translator.translate(text)\n",
    "    except RuntimeError:\n",
    "        result = text\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph TD\n",
      "  input_mic_0_en[input_mic_0_en<br>0 : 44100]\n",
      "  resampler_input_0_en[resampler_input_0_en<br>0 : 44100]\n",
      "  resampler_output_1[resampler_output_1<br>]\n",
      "  output_device_1_ru[output_device_1_ru<br>]\n",
      "  resampler_output_1[resampler_output_1<br>]\n",
      "  output_file_1_ru[output_file_1_ru<br>]\n",
      "  mixer_1_ru[mixer_1_ru<br>]\n",
      "  resampler_output_1[resampler_output_1<br>]\n",
      "  mixer_0_ru[mixer_0_ru<br>]\n",
      "  output_file_0_ru[output_file_0_ru<br>]\n",
      "  converter_0_en_ru[converter_0_en_ru<br>]\n",
      "  mixer_1_ru[mixer_1_ru<br>]\n",
      "  resampler_input_0_en[resampler_input_0_en<br>]\n",
      "  converter_0_en_ru[converter_0_en_ru<br>]\n",
      "  input_mic_0_en[input_mic_0_en<br>0 : 44100]\n",
      "  output_file_mic[output_file_mic<br>0 : 44100]\n",
      "  input_mic_0_en --> resampler_input_0_en\n",
      "  resampler_output_1 --> output_device_1_ru\n",
      "  resampler_output_1 --> output_file_1_ru\n",
      "  mixer_1_ru --> resampler_output_1\n",
      "  mixer_0_ru --> output_file_0_ru\n",
      "  converter_0_en_ru --> mixer_1_ru\n",
      "  resampler_input_0_en --> converter_0_en_ru\n",
      "  input_mic_0_en --> output_file_mic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mermaid graph\n",
    "\n",
    "def get_graph(edges):\n",
    "    # Генерация Mermaid-кода\n",
    "    result = f\"graph TD\\n\"\n",
    "    get_params = lambda x: \" : \".join([\n",
    "        str(x) \n",
    "        for x in (\n",
    "            edge_from.get(\"device\"), \n",
    "            edge_from.get(\"stream\", {}).get(\"rate\")\n",
    "        )\n",
    "        if x is not None\n",
    "    ])\n",
    "    for edge_from, edge_to in edges:\n",
    "        result += f'  {edge_from[\"name\"]}[{edge_from[\"name\"]}<br>{get_params(edge_from)}]\\n'\n",
    "        result += f'  {edge_to[\"name\"]}[{edge_to[\"name\"]}<br>{get_params(edge_to)}]\\n'\n",
    "        \n",
    "        \n",
    "    for edge_from, edge_to in edges:\n",
    "        result += f'  {edge_from[\"name\"]} --> {edge_to[\"name\"]}\\n'\n",
    "\n",
    "    return f\"{result}\"\n",
    "\n",
    "sample = [({'name': 'input_mic_0_en', 'node_type': 'input_channel', 'device': 0, 'channel': 1, 'stream': {'language': 'en', 'rate': 44100, 'audio_format': {'format_type': 'int16'}}}, {'name': 'resampler_input_0_en', 'node_type': 'resampler', 'to_rate': 16000}), ({'name': 'resampler_output_1', 'node_type': 'resampler', 'to_rate': 44100}, {'name': 'output_device_1_ru', 'device': 1, 'channel': 1, 'stream': {'language': 'ru', 'audio_format': {'format_type': 'int16'}, 'rate': 44100}, 'node_type': 'output_channel'}), ({'name': 'resampler_output_1', 'node_type': 'resampler', 'to_rate': 44100}, {'name': 'output_file_1_ru', 'node_type': 'output_file', 'path': 'samples/translated_output.wav', 'stream': {'language': 'ru', 'audio_format': {'format_type': 'int16'}, 'rate': 44100}}), ({'name': 'mixer_1_ru', 'node_type': 'mixer'}, {'name': 'resampler_output_1', 'node_type': 'resampler', 'to_rate': 44100}), ({'name': 'mixer_0_ru'}, {'name': 'output_file_0_ru'}), ({'name': 'converter_0_en_ru', 'node_type': 'converter_seamless', 'server_url': 'https://09f1-91-73-240-61.ngrok-free.app', 'log_file': 'session.log', 'config': {'stt': {'lang': 'en', 'stop_words': ['DimaTorzok', 'субтитры сделал', 'субтитры делал', 'M.K.'], 'buffer_min_words_size': 6, 'buffer_timeout_seconds': 1.0}, 'translate': {'lang_from': 'en', 'lang_to': 'ru', 'llm_call_timeout': 15.0, 'context_window': 4, 'forced_line_end': '...', 'escaped_characters': ['\\n', '\\r', '\\t', '...'], 'language_map': {'ru': 'Russian', 'en': 'English'}, 'text_template': 'I want you to act as a skilled translator.\\nI will provide you with:\\n- the original context (previous parts in the source language),\\n- the translated context (previous parts translated into the target language),\\n- the source and target languages,\\n- the next part to translate (new input in the source language).\\n\\nYour task is to:\\n1. Translate the \"next part to translate\" into the target language, without any additional explanations or comments, only the translated phrase.\\n2. Ensure that the translation is consistent with the \"original context\" and continues seamlessly from the \"translated context\".\\n3. If there are words or phrases in the original context that are missing in the translated context, do not retranslate them. Focus only on translating the \"next part to translate\".\\n4. Provide the translation as a direct continuation of the translated context.\\n\\nOriginal context (source language): {source_context}\\nTranslated context (target language): {translated_context}\\nSource language: {lang_from}\\nTarget language: {lang_to}\\nNext part to translate (source language): {text}', 'correction_template': ''}, 'tts': {'lang': 'ru', 'gap_size_bytes': 12000, 'voice_map': {'en': ['piper', 'hfc_male'], 'ru': ['piper', 'ruslan']}}}}, {'name': 'mixer_1_ru', 'node_type': 'mixer'}), ({'name': 'resampler_input_0_en', 'node_type': 'resampler', 'to_rate': 16000}, {'name': 'converter_0_en_ru', 'node_type': 'converter_seamless', 'server_url': 'https://09f1-91-73-240-61.ngrok-free.app', 'log_file': 'session.log', 'config': {'stt': {'lang': 'en', 'stop_words': ['DimaTorzok', 'субтитры сделал', 'субтитры делал', 'M.K.'], 'buffer_min_words_size': 6, 'buffer_timeout_seconds': 1.0}, 'translate': {'lang_from': 'en', 'lang_to': 'ru', 'llm_call_timeout': 15.0, 'context_window': 4, 'forced_line_end': '...', 'escaped_characters': ['\\n', '\\r', '\\t', '...'], 'language_map': {'ru': 'Russian', 'en': 'English'}, 'text_template': 'I want you to act as a skilled translator.\\nI will provide you with:\\n- the original context (previous parts in the source language),\\n- the translated context (previous parts translated into the target language),\\n- the source and target languages,\\n- the next part to translate (new input in the source language).\\n\\nYour task is to:\\n1. Translate the \"next part to translate\" into the target language, without any additional explanations or comments, only the translated phrase.\\n2. Ensure that the translation is consistent with the \"original context\" and continues seamlessly from the \"translated context\".\\n3. If there are words or phrases in the original context that are missing in the translated context, do not retranslate them. Focus only on translating the \"next part to translate\".\\n4. Provide the translation as a direct continuation of the translated context.\\n\\nOriginal context (source language): {source_context}\\nTranslated context (target language): {translated_context}\\nSource language: {lang_from}\\nTarget language: {lang_to}\\nNext part to translate (source language): {text}', 'correction_template': ''}, 'tts': {'lang': 'ru', 'gap_size_bytes': 12000, 'voice_map': {'en': ['piper', 'hfc_male'], 'ru': ['piper', 'ruslan']}}}}), ({'name': 'input_mic_0_en', 'node_type': 'input_channel', 'device': 0, 'channel': 1, 'stream': {'language': 'en', 'rate': 44100, 'audio_format': {'format_type': 'int16'}}}, {'name': 'output_file_mic', 'node_type': 'output_file', 'path': 'samples/source_input.wav', 'stream': {'language': 'ru', 'audio_format': {'format_type': 'int16'}, 'rate': 44100}})]\n",
    "print(get_graph(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_audio\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from pysepm import pesq, stoi\n",
    "\n",
    "\n",
    "def analyze_audio(file_path, reference_path=None, sr_target=16000):\n",
    "    \"\"\"\n",
    "    Анализирует качество аудио на основе объективных метрик.\n",
    "    :param file_path: Путь к аудиофайлу для анализа.\n",
    "    :param reference_path: Путь к эталонному аудио (если доступно).\n",
    "    :param sr_target: Частота дискретизации для анализа (по умолчанию 16 кГц для PESQ).\n",
    "    :return: Словарь с метриками качества.\n",
    "    \"\"\"\n",
    "    # Загружаем аудио\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    print(f\"Загружен файл: {file_path}, длина {len(y) / sr:.2f} сек, частота {sr} Гц\")\n",
    "    \n",
    "    # Если есть эталонное аудио, загружаем его\n",
    "    ref_y = None\n",
    "    if reference_path:\n",
    "        ref_y, ref_sr = librosa.load(reference_path, sr=None)\n",
    "        # Приводим эталонное аудио к той же длине, что и тестовое\n",
    "        if len(ref_y) > len(y):\n",
    "            ref_y = ref_y[:len(y)]\n",
    "        elif len(ref_y) < len(y):\n",
    "            y = y[:len(ref_y)]\n",
    "    \n",
    "    # Пересэмплинг для анализа\n",
    "    y_resampled = librosa.resample(y, orig_sr=sr, target_sr=sr_target)\n",
    "    if ref_y is not None:\n",
    "        ref_y_resampled = librosa.resample(ref_y, orig_sr=ref_sr, target_sr=sr_target)\n",
    "    else:\n",
    "        ref_y_resampled = None\n",
    "\n",
    "    # Инициализация метрик\n",
    "    metrics = {}\n",
    "\n",
    "    # 1. SNR (Signal-to-Noise Ratio)\n",
    "    signal_power = np.mean(y_resampled**2)\n",
    "    noise_power = np.var(y_resampled - ref_y_resampled) if ref_y_resampled is not None else None\n",
    "    metrics['SNR (dB)'] = 10 * np.log10(signal_power / noise_power) if noise_power else None\n",
    "\n",
    "    # 2. PESQ (если есть эталонное аудио)\n",
    "    if ref_y_resampled is not None:\n",
    "        metrics['PESQ'] = pesq(ref_y_resampled, y_resampled, sr_target)\n",
    "\n",
    "    # 3. STOI (если есть эталонное аудио)\n",
    "    if ref_y_resampled is not None:\n",
    "        metrics['STOI'] = stoi(ref_y_resampled, y_resampled, sr_target)\n",
    "\n",
    "    # 4. Spectral Centroid (средняя частота спектра)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    metrics['Average Spectral Centroid (Hz)'] = np.mean(spectral_centroid)\n",
    "\n",
    "    # 5. Zero Crossing Rate (Частота пересечения нуля)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=y)\n",
    "    metrics['Zero Crossing Rate'] = np.mean(zcr)\n",
    "\n",
    "    # 6. RMS Energy (корень среднего квадрата)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    metrics['Average RMS Energy'] = np.mean(rms)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log handlers\n",
    "\n",
    "def fdt(dt):\n",
    "    return dt.strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "\n",
    "def audio_bytes_handler(match, metrics, dt):\n",
    "    metrics[\"total_audio_bytes\"] += int(match.group(1))\n",
    "\n",
    "def task_completed_handler(match, metrics, dt):\n",
    "    metrics[\"total_tasks\"] += 1\n",
    "\n",
    "def stt_handler(match, metrics, dt):\n",
    "    value = match.group(1)\n",
    "\n",
    "    metrics[\"texts\"][\"stt\"].append(value)\n",
    "\n",
    "    metrics[\"buffer\"].append((dt, \"stt\", value))\n",
    "\n",
    "def stti_handler(match, metrics, dt):\n",
    "    value = match.group(1)\n",
    "\n",
    "    metrics[\"texts\"][\"stti\"].append(value)\n",
    "\n",
    "    metrics[\"buffer\"].append((dt, \"stti\", value))\n",
    "\n",
    "def llm_handler(match, metrics, dt):\n",
    "    value = match.group(1)\n",
    "\n",
    "    metrics[\"texts\"][\"llm\"].append(value)\n",
    "\n",
    "    metrics[\"buffer\"].append((dt, \"llm\", value))\n",
    "\n",
    "def tts_handler(match, metrics, dt):\n",
    "    value = match\n",
    "\n",
    "    duration = (metrics[\"buffer\"][-1][0] - metrics[\"buffer\"][0][0]).total_seconds()\n",
    "    metrics[\"processing_time\"].append(duration)\n",
    "\n",
    "    metrics[\"texts\"][\"tts\"].append(value)\n",
    "\n",
    "    metrics[\"buffer\"].append((dt, \"tts\", value))\n",
    "    metrics[\"chunks\"].append(metrics[\"buffer\"])\n",
    "    metrics[\"buffer\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERNS_MAP = {\n",
    "    r\"Received audio bytes (\\d+)\": audio_bytes_handler,\n",
    "    r\"Yielding item (\\d+)\": task_completed_handler,\n",
    "    r\"root\\.\\[STT\\]: [^ ]+ Received response  (.+)\": stt_handler,\n",
    "    r\"root\\.\\[STT\\]: [^ ]+ Received transcription: (.+)\": stti_handler,\n",
    "    r\"root\\.\\[LLM\\]: [^ ]+ Sent translation: (.+)\": llm_handler,\n",
    "    r\"root\\.\\[TTS\\]: [^ ]+ Synthesizing text using .+\": tts_handler,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_log\n",
    "\n",
    "def parse_log(log_file_path):\n",
    "    \"\"\"\n",
    "    Parses a log file and extracts key metrics for report generation.\n",
    "    :param log_file_path: Path to the log file.\n",
    "    :return: Dictionary containing aggregated metrics.\n",
    "    \"\"\"\n",
    "    # Инициализация метрик\n",
    "    metrics = {\n",
    "        \"total_audio_bytes\": 0,\n",
    "        \"total_tasks\": 0,\n",
    "        \"processing_time\": [],\n",
    "        \"errors\": [],\n",
    "        \"buffer\": [],\n",
    "        \"chunks\": [],\n",
    "        \"texts\": defaultdict(list),\n",
    "    }\n",
    "\n",
    "    def process_line(line, metrics):\n",
    "        handler, params = getattr(process_line, \"future\", None) or [None, {}]\n",
    "        if callable(handler):\n",
    "            handler(line, metrics, **params)\n",
    "            setattr(process_line, \"future\", None)\n",
    "            return\n",
    "\n",
    "        for pattern, handler in PATTERNS_MAP.items():\n",
    "            match = re.search(pattern, line)\n",
    "            if not match:\n",
    "                continue\n",
    "            \n",
    "            dt = datetime.fromisoformat(line[:26])\n",
    "            if handler == tts_handler:\n",
    "                setattr(process_line, \"future\", (handler, {\"dt\": dt}))\n",
    "            else:\n",
    "                handler(match, metrics, dt)\n",
    "\n",
    "            return\n",
    "\n",
    "    with open(log_file_path, \"r\") as fp:\n",
    "        [process_line(x, metrics) for x in fp]\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_html_report\n",
    "from jinja2 import Template\n",
    "\n",
    "def generate_html_report(report_data, output_file):\n",
    "    \"\"\"\n",
    "    Генерирует HTML-страницу отчёта с использованием Jinja2 и Bootstrap.\n",
    "    \n",
    "    :param report_data: Словарь с данными отчёта\n",
    "    :param output_file: Путь до выходного HTML-файла\n",
    "    \"\"\"\n",
    "    # HTML-шаблон с использованием Bootstrap\n",
    "    with open(\"report.html\", \"r\") as fp:\n",
    "        html_template = fp.read()\n",
    "\n",
    "    # Создание шаблона\n",
    "    template = Template(html_template)\n",
    "\n",
    "    # Генерация HTML-кода\n",
    "    html_content = template.render(report_data=report_data)\n",
    "\n",
    "    # Запись HTML в файл\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"Отчёт сохранён в файл: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_report\n",
    "\n",
    "def generate_report(metrics, output_file):\n",
    "     # Конфиг\n",
    "    with open(config_file, \"r\") as fp:\n",
    "        config = json.load(fp)\n",
    "\n",
    "    nodes = {\n",
    "        x[\"name\"]: x \n",
    "        for x in config[\"nodes\"]\n",
    "    }\n",
    "\n",
    "    config_source_output = nodes.get(\"output_file_mic\")\n",
    "    audio_source_file = str(PROJECT_ROOT / config_source_output.get(\"path\"))\n",
    "\n",
    "    key = \"output_file_1_ru\"\n",
    "    config_result_output = nodes.get(key)\n",
    "    audio_output_file = str(PROJECT_ROOT / config_result_output.get(\"path\"))\n",
    "    \n",
    "    key = \"converter_0_en_ru\"\n",
    "    config_converter = nodes.get(key)\n",
    "\n",
    "    # Граф узлов\n",
    "    edges = [\n",
    "        (nodes.get(k1, {\"name\": k1}), nodes.get(k2, {\"name\": k2})) \n",
    "        for k1, k2 in config[\"edges\"]\n",
    "    ]\n",
    "\n",
    "    graph = get_graph(edges)\n",
    "    \n",
    "    # Агрегируем среднее время обработки\n",
    "    average_time = int((\n",
    "        sum(metrics[\"processing_time\"]) / len(metrics[\"processing_time\"]) \n",
    "        if metrics[\"processing_time\"] else \n",
    "        0\n",
    "    ) * 1000)\n",
    "    \n",
    "    # Готовим чанки\n",
    "    chunks = metrics[\"chunks\"]\n",
    "\n",
    "    # Форматируем время для удобного чтения\n",
    "    chunks = [\n",
    "        [(fdt(x[0]), x[1], x[2]) for x in block]\n",
    "        for block in chunks\n",
    "    ]\n",
    "\n",
    "    # Собираем все чанки\n",
    "    chunks = [\n",
    "        [\";\".join(x) for x in block] \n",
    "        for block in chunks\n",
    "    ]\n",
    "\n",
    "    # Собираем полные тексты\n",
    "    texts = {\n",
    "        k: \" \".join([x.strip() for x in v]) \n",
    "        for k, v in metrics[\"texts\"].items()\n",
    "    }\n",
    "\n",
    "    # Считаем BLEU для текста переведенного по полному тексту от TTS\n",
    "    if \"ref_stt\" not in texts:\n",
    "        texts[\"ref_stt\"] = translate(\n",
    "            texts[\"stti\"][:500],\n",
    "            config_converter[\"config\"][\"translate\"][\"lang_from\"],\n",
    "            config_converter[\"config\"][\"translate\"][\"lang_to\"],\n",
    "        )\n",
    "    bleu_stt = calculate_bleu(texts[\"ref_stt\"], texts[\"ref_stt\"])\n",
    "\n",
    "    # Считаем BLEU для эталонного перевода\n",
    "    bleu_ref = \"No reference translation provided\"\n",
    "    if transalation_file:\n",
    "        with open(transalation_file, \"r\") as fp:\n",
    "            texts[\"ref\"] = fp.read()\n",
    "            \n",
    "        bleu_ref = calculate_bleu(texts[\"ref\"], texts[\"tts\"])\n",
    "\n",
    "    bleu_ref_ref_stt = calculate_bleu(texts[\"ref\"], texts[\"ref_stt\"])\n",
    "    \n",
    "    # Формируем финальный отчёт\n",
    "    report = {\n",
    "        \"full_config\": config,\n",
    "        \"converter_config\": json.dumps(config_converter, indent=4, ensure_ascii=False),\n",
    "        \"graph\": graph,\n",
    "        \"source_audio\": audio_source_file,\n",
    "        \"result_audio\": audio_output_file,\n",
    "        \"bytes_total\": metrics[\"total_audio_bytes\"],\n",
    "        \"tasks_total\": metrics[\"total_tasks\"],\n",
    "        \"processing_time_avg\": average_time,\n",
    "        \"chunks\": chunks,\n",
    "        \"texts\": texts,\n",
    "        \"bleu\": [\n",
    "            [\"Перевод\", \"На озвучке\", bleu_ref],\n",
    "            [\"Автоматический перевод 500 символов\", \"На озвучке\", bleu_stt],\n",
    "            [\"Перевод\", \"Автоматический перевод 500 символов\", bleu_ref_ref_stt],\n",
    "        ],\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "    }\n",
    "    \n",
    "    # Сохраняем отчёт в JSON\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump(report, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Report saved to {output_file}\")\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original log from /Users/tug/Downloads/leo_mic (4).log\n",
      "Report saved to /Users/tug/Downloads/report.json\n",
      "Отчёт сохранён в файл: /Users/tug/Downloads/report.html\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Пути к лог-файлу и отчёту\n",
    "print(\"Original log from\", log_file)\n",
    "\n",
    "# Парсим лог и создаём отчёт\n",
    "metrics = parse_log(log_file)\n",
    "report_data = generate_report(metrics, report_raw_file)\n",
    "generate_html_report(report_data, report_html_file)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synchro-python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
